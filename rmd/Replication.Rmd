---
title: "Replication of BKR"
author: "Shunsuke Matsuno"
date: "2020/6/1"
output:
  html_document:
    code_folding: show
    df_print: paged
    number_sections: no
    theme: united
    toc: yes
    toc_float: no
  pdf_document:
    toc: yes
---

```{r settings, echo=FALSE}
### Setting the global code chunk options ###
# Args
#   comment='': won't append any string to the start of each line of results
#   fig.align='center': align figures to the center of document
knitr::opts_chunk$set(comment="", fig.align="center", warning = FALSE)
```
# Required libraries
```{r}
easypackages::libraries('tidyverse', 'ggplot2','NumbersGame')
```


# Introduction
- This note replicates Bird, Karolyi, and Ruchti (BKR; 2019, JAE).

# Simulating the data
- Since I don't have access to the original data, I simulate the "observed" data using the estimated parameters in BKR.

## Parameters
- $\theta = (\eta, \gamma, \psi^2, \zeta)$
```{r}
set.seed(2020)

# Table 4
eta <- 0.0161   # marginal cost
gamma <- 2.0817    # curvature
psi2 <- 0.8201   # variance
zeta <- 3.7105    # variance multiplier
theta <- c(eta, gamma, psi2, zeta)

```
## Benefit function
- Since the estimates of full model (coefficients on polynomials) are not reported, I approximate the capital market benefit function by `compute_benefit.R`.

## Latent earnings distribution
- I assume that latent earnings distribution is generated by normal distribution.
- For the computational ease, I set the number of firms (observations) to $1,000$.
    - In BKR, the number of observations is $49,604$.
    - To get more clear histograms, try set $N=10,000$.
```{r}
# number of firms
N <- 10000
sigma <- 5

df_firm <- tibble(
  firm = 1:N,
  e = extraDistr::rdnorm(N, mean = 0, sd = sigma) # latent earnings surprize
  ) %>% 
  mutate(bin_normalized  = e + (20 + 1))    # the left-end bin is normalized (labeled) as 1
df_firm

ggplot(df_firm, aes(x = e)) +
  geom_bar() +
  xlim(-21, 21)
```

## Manipulation
- Each firm decides the amount of manipulation, $m$, according to the maximization problem.
- `compute_utility` computes the following utility:
$$
u_{\text {Discrete}}(b, m, \theta)=\sum_{-20}^{20} \phi_{m, \theta}(\varepsilon) \mathcal{B}(b+m+\varepsilon) d \varepsilon-\beta_{b} m^{\gamma}
$$
```{r}
df_firm_utility <- compute_optimal_manipulation_simulated(df_firm, theta)
df_firm_utility
```

```{r}
# plot
plot_latent_reported(df_firm_utility)
```

- The 'empirical' distribution of earnings surprises, $R$, is a bit drastic than the actual empirical distribution.
    - Compare the following graph with Fig.2.
    - This is because my simulation assumes that the empirical distribution is solely determined by the optimization behavior of BKR's model, while in reality variety of other factors come into play.
    
```{r}
qplot(df_firm_utility$R, geom = 'bar', xlim = c(-11,11))
```

- See what happens if we increase the marginal cost parameter, $\eta$.
    - Since manipulation becomes more costly, firms that find manipulation beneficial are limited to just below the zero threshold.
```{r}
theta_new <- theta
theta_new[1] <- 0.5

df_firm_utility <- compute_optimal_manipulation_simulated(df_firm, theta = theta_new)
plot_latent_reported(df_firm_utility)
```

# Estimation
- Regarding the simulated data as 'observed' data, I recover the parameter $\theta$ by BKR method.
- See `SummaryBKR.pdf` for the step-by-step estimation procedure.
```{r}
df_observed <- df_firm_utility %>%      # df_firm_utility is the 'true' data
  select(firm, R)                       # Discard the information that cannot be observed (by researcher)
df_observed
```
## Step 1. Candidate $\theta$
- I set the initial $\theta$ to be the true $\theta$.
```{r}
theta_init <- theta
```

## Step 2. Simulate optimal firm behavior
- Considering the computational cost, I set the number of simulations $S$ to be $1,000$.
    - The original paper uses $S=10,000$.
```{r, message=FALSE}
S <- 1000   # number of simulations
e_vec <- -20:-1    # only firms with negative state considers manipulation
result <- array(dim = c(S, length(e_vec), 2))   # S x 20 x 2 array
for(i in seq_along(e_vec)){
  result_temp <- compute_optimal_manipulation_for_e(e_vec[i], benefit, theta_init)
  result[,i,1] <- result_temp$m_opt    # the 1st elt of 3rd dim is m_opt
  result[,i,2] <- result_temp$eps      # the 2nd elt of 3rd dim is epsilon
}

# transform the result matrix to data frame.
colnames_e <- as.character(-20:-1)    # column names are states (bins)
df_result_m <- data.frame(result[,,1])
df_result_eps <- data.frame(result[,,2])
colnames(df_result_m) <- colnames_e
colnames(df_result_eps) <- colnames_e

# transform to long data
df_result_m_long <- df_result_m %>% 
  pivot_longer(cols = everything(), names_to = 'e', values_to = 'm') %>% 
  mutate(e = as.integer(e))
df_result_eps_long <- df_result_eps %>% 
  pivot_longer(cols = everything(), names_to = 'e', values_to = 'eps') %>% 
  mutate(e = as.integer(e))

# bind both data for m and eps
df_result_long <- bind_cols(df_result_m_long, df_result_eps_long) %>% 
  select(e, m, eps)
```

- Next, I compute the transition matrix, $P$.
```{r}
P <- array(dim = c(20, 20))

for(jj in 1:NROW(P)){
  # computes each row of P
  p_b_j <- df_result_long %>% 
    mutate(j = pmap_int(.l = ., .f = compute_transition, j = jj)) %>% 
    group_by(e) %>% 
    summarise(p_b_j = sum(j) / S) %>% 
    pull(p_b_j)  
  P[jj,] <- p_b_j
}

```

